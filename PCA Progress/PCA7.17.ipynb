{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(testfilepath,trainfilepath,predictfilepath):\n",
    "    data_test=pd.read_csv(testfilepath,index_col=False)\n",
    "    data_train=pd.read_csv(trainfilepath,index_col=False)\n",
    "    data_pred=pd.read_csv(predictfilepath,index_col=False)\n",
    "    data_pred=data_pred[data_pred.RegionName.apply(lambda x:x[-7:][:4])=='2019']\n",
    "    data_trainx=data_train.iloc[:,4:]\n",
    "    data_testx=data_test.iloc[:,4:]\n",
    "    data_predx=data_pred.iloc[:,4:]\n",
    "    train_y=data_train.iloc[:,3]\n",
    "    test_y=data_test.iloc[:,3]\n",
    "    pred_y=data_pred.iloc[:,3]\n",
    "    pred_y=np.log(pred_y)\n",
    "    test_y=np.log(test_y)\n",
    "    train_y=np.log(train_y)\n",
    "    #fit pca w max components \n",
    "    # pca (stands for perfect charming angel <3)\n",
    "    pca = PCA(n_components=10,random_state=100)\n",
    "    pca.fit(data_trainx)\n",
    "\n",
    "    #how many components to explain 95% of variance \n",
    "    i=0\n",
    "    cum_exp_var=0\n",
    "    while cum_exp_var<.95:\n",
    "\n",
    "        cum_exp_var+=pca.explained_variance_ratio_[i]\n",
    "        i+=1\n",
    "\n",
    "\n",
    "    #refit pca w # components that explain 95% variance \n",
    "    pca = PCA(n_components=i,random_state=100)\n",
    "    pca.fit(data_trainx)\n",
    "    pca_train=pca.transform(data_trainx)\n",
    "    pca_train=pd.DataFrame(data=pca_train)\n",
    "    pca_test=pca.transform(data_testx)\n",
    "    pca_test=pd.DataFrame(data=pca_test)\n",
    "    pca_pred=pca.transform(data_predx)\n",
    "    pca_pred=pd.DataFrame(data=pca_pred)\n",
    "    \n",
    "    #add back logged y vals\n",
    "    pca_pred['Log_Rent']=pred_y\n",
    "    pca_test['Log_Rent']=test_y  \n",
    "    pca_train['Log_Rent']=train_y\n",
    "\n",
    "        \n",
    "    return [pca_test,pca_train,pca_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##JULY 17\n",
    "\n",
    "#pca on full acs and our new hospitals gov buildings businesses data\n",
    "[pca_test,pca_train,pca_pred]=do_pca('TESTDATAnewcols7.17_3yearPCA.csv','TRAINDATAnewcols7.17_3yearPCA.csv','PREDICTDATAnewcols7.17_3yearPCA.csv')\n",
    "pca_test= pd.DataFrame(pca_test)\n",
    "pca_train= pd.DataFrame(pca_train)\n",
    "pca_pred= pd.DataFrame(pca_pred)\n",
    "pca_test.to_csv('Results/TESTDATAnewcols7.17_3yearPCAfull.csv',index=False)\n",
    "pca_train.to_csv('Results/TRAINDATAnewcols7.17_3yearPCAfull.csv',index=False)\n",
    "pca_pred.to_csv('Results/PREDICTDATAnewcols7.17_3yearPCAfull.csv',index=False)\n",
    "\n",
    "\n",
    "#pca on selected/modified acs and our new hospitals gov buildings businesses data\n",
    "[pca_test,pca_train,pca_pred]=do_pca('TESTDATAnewcols7.17_3year.csv','TRAINDATAnewcols7.17_3year.csv','PREDICTDATAnewcols7.17_3year.csv')\n",
    "\n",
    "pca_test.to_csv('Results/TESTDATAnewcols7.17_3yearPCApartial.csv',index=False)\n",
    "pca_train.to_csv('Results/TRAINDATAnewcols7.17_3yearPCApartial.csv',index=False)\n",
    "pca_pred.to_csv('Results/PREDICTDATAnewcols7.17_3yearPCApartial.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JULY 19\n",
    "\n",
    "#pca on selected/modified acs and our new hospitals gov buildings businesses data\n",
    "[pca_test,pca_train,pca_pred]=do_pca('TESTDATAnewcols7.18_3year.csv','TRAINDATAnewcols7.18_3year.csv','PREDICTDATAnewcols7.18_3year.csv')\n",
    "\n",
    "\n",
    "pca_test.to_csv('Results/TESTDATAnewcols7.18_3yearPCApartial.csv',index=False)\n",
    "pca_train.to_csv('Results/TRAINDATAnewcols7.18_3yearPCApartial.csv',index=False)\n",
    "pca_pred.to_csv('Results/PREDICTDATAnewcols7.18_3yearPCApartial.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #lasso on pca\n",
    "\n",
    "# std_scaler=StandardScaler()\n",
    "# train_X_scaled = std_scaler.fit_transform(pca_train)\n",
    "# test_X_scaled = std_scaler.transform(pca_test)\n",
    "# pred_X_scaled=std_scaler.transform(pca_pred)\n",
    "\n",
    "# #copied from ryans lasso code\n",
    "# # Create and fit the model\n",
    "# lasso = Lasso(normalize=False)\n",
    "# lasso_params = {'alpha':np.linspace(0,10,100)}\n",
    "# grid_lasso = GridSearchCV(lasso, lasso_params, scoring='r2', n_jobs=-1, cv=5, verbose=2)\n",
    "# grid_lasso.fit(train_X_scaled, train_y)\n",
    "    \n",
    "# # Tell user alpha used\n",
    "# print('Best alpha: ', grid_lasso.best_params_['alpha'])\n",
    "    \n",
    "# # Tell user training score\n",
    "# print('Score on training data: ', round(grid_lasso.score(train_X_scaled,train_y),3))\n",
    "\n",
    "    \n",
    "# # Tell user the croo-validation scores\n",
    "# print('Scores from 5-fold cross-validation: \\n', cross_val_score(grid_lasso, train_X_scaled, train_y, scoring='r2', n_jobs=-1, cv=5))\n",
    "    \n",
    "# # Tell user the test score\n",
    "# print('Score on TEST data: ', round(grid_lasso.score(test_X_scaled,test_y),3))\n",
    "    \n",
    "    \n",
    "# # Tell user pred score\n",
    "# print('Score on pred data: ', round(grid_lasso.score(pred_X_scaled,pred_y),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scoretest=[]\n",
    "# Scoretrain=[]\n",
    "# Scorepred=[]\n",
    "# alphrange=np.linspace(0,10,100)\n",
    "# for i in alphrange:\n",
    "       \n",
    "#     lasso = Lasso(normalize=False,alpha=i)\n",
    "#     lasso.fit(train_X_scaled, train_y)\n",
    "#     Scoretest.append(lasso.score(test_X_scaled,test_y))\n",
    "#     Scoretrain.append(lasso.score(train_X_scaled,train_y))\n",
    "#     Scorepred.append(lasso.score(pred_X_scaled,pred_y))\n",
    "# print('best alpha for test r2 is ',alphrange[Scoretest.index(max(Scoretest))])\n",
    "# print('train and test ',Scoretrain[Scoretest.index(max(Scoretest))],Scoretest[Scoretest.index(max(Scoretest))],Scorepred[Scoretest.index(max(Scoretest))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pca on our subsect of data 30 ish cols "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
